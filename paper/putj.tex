% -----------------------------------------------
% Template for ISMIR Papers
% 2015 version, based on previous ISMIR templates
% -----------------------------------------------

\documentclass{article}
\usepackage{ismir}
\usepackage{url}
\usepackage{cleveref}
\usepackage{cite}
\usepackage{brian}
\usepackage{graphicx}
\usepackage{booktabs}

% Title.
% ------
\title{Pump up the JAMS}


% Single address
% To use with only one author or several with the same address
% ---------------
%\oneauthor
% {Names should be omitted for double-blind reviewing}
% {Affiliations should be omitted for double-blind reviewing}

% Two addresses
% --------------
%\twoauthors
%  {First author} {School \\ Department}
%  {Second author} {Company \\ Address}

% Three addresses
% --------------
\threeauthors
  {First author} {Affiliation1 \\ {\tt author1@ismir.edu}}
  {Second author} {\bf Retain these fake authors in\\\bf submission to preserve the formatting}
  {Third author} {Affiliation3 \\ {\tt author3@ismir.edu}}

% Four addresses
% --------------
%\fourauthors
%  {First author} {Affiliation1 \\ {\tt author1@ismir.edu}}
%  {Second author}{Affiliation2 \\ {\tt author2@ismir.edu}}
%  {Third author} {Affiliation3 \\ {\tt author3@ismir.edu}}
%  {Fourth author} {Affiliation4 \\ {\tt author4@ismir.edu}}

\begin{document}
%
\maketitle
%
\begin{abstract}
Predictive models for music annotation tasks are practically limited by a paucity of
well-annotated training data.
In this work, we develop a general framework for augmenting annotated musical datasets,
allowing practitioners to expand training sets in a controlled fashion.
We investigate the effects of data augmentation on the task of instrument recognition in
mixtures.
\end{abstract}
%
\section{Introduction}
\label{sec:introduction}

\cite{sturmkiki}

\subsection{Our contributions}

\section{Data augmentation}

\cite{mauch2013audio}

\subsection{Audio deformation}

\subsection{Annotation deformation}

\cite{humphreyjams}

\section{Example: instrument recognition}

\cite{bittner2014medleydb}

\subsection{Data augmentation}

The data augmentation pipeline consists of four stages:

\begin{description}
    \item[Pitch shift] by $n \in \{-1, 0, +1\}$ semitones
    \item[Time stretch] by a factor of $f \in \left\{ 2^{-1/2}, 1.0, 2^{1/2}\right\}$
    \item[Background noise] under four conditions: no noise,
        subway\footnote{\url{https://www.freesound.org/people/jobro/sounds/112252/}},
        crowded concert hall\footnote{\url{https://www.freesound.org/people/klankbeeld/sounds/171317/}},
        and night-time city noise\footnote{\url{https://www.freesound.org/people/inkhorn/sounds/231870/}}.
        The latter three were mixed with random weights drawn uniformly in $[0.1, 0.4]$.
    \item[Dynamic range compression] under three preset conditions drawn from the {Dolby E}
        standards~\cite{dolbyE}: none, \emph{speech},
        and \emph{music (standard)}.
\end{description}

Combining all stages of the pipeline produces 108 variants of each input track.  To
simplify the experiments, we only compare the cumulative effects of the above
augmentations.  This results in five training conditions:
\begin{enumerate}
    \item No augmentation;
        \vspace{-.5\baselineskip}
    \item Pitch shift;
        \vspace{-.5\baselineskip}
    \item Pitch shift and time stretch;
        \vspace{-.5\baselineskip}
    \item Pitch shift, time stretch, and background noise;
        \vspace{-.5\baselineskip}
    \item All stages.
\end{enumerate}
Note that each stage contains an identity transformation (\eg, shift by $0$ semitones),
so that each configuration is contained within all subsequent configurations.

\subsection{Acoustic model}

TODO: fill this in

\subsection{Results}

\section{Conclusion}

% For bibtex users:
\bibliography{refs}

\end{document}
